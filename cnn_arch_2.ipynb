{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import data_utils as my_utils\n",
    "import cv2\n",
    "import dlib\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import keras\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Activation, BatchNormalization, Conv2D, Dense, Dropout, Flatten, Input, MaxPool2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.utils import np_utils\n",
    "from skimage.feature import hog\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"fer2013.csv\")\n",
    "emotion_labels = {0: \"Angry\", 1: \"Disgust\", 2:\"Fear\", 3:\"Happy\", 4:\"Sad\", 5:\"Surprise\", 6:\"Neutral\"}\n",
    "labels = [\"Angry\", \"Disgust\", \"Fear\", \"Happy\", \"Sad\", \"Surprise\", \"Neutral\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>pixels</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion                                             pixels     Usage\n",
       "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
       "1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
       "2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
       "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
       "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Training       28709\n",
       "PublicTest      3589\n",
       "PrivateTest     3589\n",
       "Name: Usage, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Usage\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    8989\n",
       "6    6198\n",
       "4    6077\n",
       "2    5121\n",
       "0    4953\n",
       "5    4002\n",
       "1     547\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"emotion\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Angry',\n",
       " 1: 'Disgust',\n",
       " 2: 'Fear',\n",
       " 3: 'Happy',\n",
       " 4: 'Sad',\n",
       " 5: 'Surprise',\n",
       " 6: 'Neutral'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritvikareddy 1/Documents/GitHub/ml-project/venv/lib/python3.6/site-packages/pandas/core/frame.py:3697: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n",
      "/Users/ritvikareddy 1/Documents/GitHub/ml-project/data_utils.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  lambda pixel_str: np.fromstring(pixel_str, sep=' '))\n"
     ]
    }
   ],
   "source": [
    "# process the training, validation and test data\n",
    "x_train, y_train = my_utils.process_data(df, 'Training')\n",
    "x_validation, y_validation = my_utils.process_data(df, 'PublicTest')\n",
    "x_test, y_test = my_utils.process_data(df, \"PrivateTest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get face landmarks\n",
    "x_train_landmarks = my_utils.extract_landmark_features(x_train)\n",
    "x_validation_landmarks = my_utils.extract_landmark_features(x_validation)\n",
    "x_test_landmarks = my_utils.extract_landmark_features(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn for just the raw pixels\n",
    "images_nn = Input(shape=(48,48,1))\n",
    "\n",
    "images_conv1 = Conv2D(64, 3, kernel_initializer='he_normal', activation='relu')(images_nn)\n",
    "images_batchnorm1 = BatchNormalization()(images_conv1)\n",
    "images_pool1 = MaxPool2D(pool_size=(3,3), strides=2)(images_batchnorm1)\n",
    "\n",
    "images_conv2 = Conv2D(128, 3, activation='relu')(images_pool1)\n",
    "images_batchnorm2 = BatchNormalization()(images_conv2)\n",
    "images_pool2 = MaxPool2D(pool_size=(3,3), strides=2)(images_batchnorm2)\n",
    "\n",
    "images_conv3 = Conv2D(256, 3, activation='relu')(images_pool2)\n",
    "images_batchnorm3 = BatchNormalization()(images_conv3)\n",
    "images_pool3 = MaxPool2D(pool_size=(3,3), strides=2)(images_batchnorm3)\n",
    "images_dropout1 = Dropout(0.6)(images_pool3)\n",
    "\n",
    "images_flat1 = Flatten()(images_dropout1)\n",
    "images_dense1 = Dense(4096, activation='relu')(images_flat1)\n",
    "images_dropout2 = Dropout(0.6)(images_dense1)\n",
    "\n",
    "images_dense2 = Dense(1024, activation='relu')(images_dropout2)\n",
    "images_batchnorm4 = BatchNormalization()(images_dense2)\n",
    "\n",
    "images_dense3 = Dense(128, activation='relu')(images_batchnorm4)\n",
    "\n",
    "\n",
    "# cnn for landmark features\n",
    "# input shape will be 68*2 (from landamrks)\n",
    "landmarks_features_nn = Input(shape=(68,2))\n",
    "landmarks_features_flat1 = Flatten()(landmarks_features_nn)\n",
    "landmarks_features_dense1 = Dense(1024, activation='relu')(landmarks_features_flat1)\n",
    "landmarks_features_batchnorm1 = BatchNormalization()(landmarks_features_dense1)\n",
    "\n",
    "landmarks_features_dense2 = Dense(128, activation='relu') (landmarks_features_batchnorm1)\n",
    "landmarks_features_batchnorm2 = BatchNormalization()(landmarks_features_dense2)\n",
    "\n",
    "# merge final outputs from both networks\n",
    "merged_net = keras.layers.merge.concatenate([images_dense3, landmarks_features_batchnorm2],\n",
    "                                           axis=-1)\n",
    "\n",
    "output_layer = Dense(7, activation='softmax')(merged_net)\n",
    "\n",
    "model = Model(inputs=[images_nn, landmarks_features_nn], outputs=output_layer)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# save best weights\n",
    "checkpoint = ModelCheckpoint(filepath='cnn_arch2_landmarks', verbose=2, save_best_only=True)\n",
    "\n",
    "# num epochs\n",
    "epochs = 10\n",
    "\n",
    "# run model\n",
    "model_history = model.fit(x_train, y_train, epochs=epochs,\n",
    "                 shuffle=True,\n",
    "                 batch_size=100, validation_data=(x_validation, y_validation),\n",
    "                 callbacks=[checkpoint], verbose=2)\n",
    "\n",
    "# save model to json\n",
    "model_json = model.to_json()\n",
    "with open(\"cnn_arch2_landmarks.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.suptitle('CNN on raw pixel data', fontsize=10)\n",
    "plt.ylabel('Loss', fontsize=16)\n",
    "plt.plot(model_history.history['loss'], color='b', label='Training Loss')\n",
    "plt.plot(model_history.history['val_loss'], color='r', label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.ylabel('Accuracy', fontsize=16)\n",
    "plt.plot(model_history.history['acc'], color='b', label='Training Accuracy')\n",
    "plt.plot(model_history.history['val_acc'], color='r', label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted_probs = model.predict(x_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Metrics: \", model.metrics_names)\n",
    "print(\"Loss on test data\", score[0])\n",
    "print(\"Test Accuracy\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_probs_to_labels(y_probs, labels):\n",
    "    predicted_label = lambda x: labels[x.argmax()]\n",
    "    return [predicted_label(each) for each in y_probs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted_labels = convert_probs_to_labels(y_predicted_probs, labels)\n",
    "y_actual_labels = convert_probs_to_labels(y_test, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "cnf_matrix = confusion_matrix(y_actual_labels, y_predicted_labels)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "plot_confusion_matrix(cnf_matrix, classes=labels,\n",
    "                      title='Confusion Matrix for Test Data')\n",
    "plt.show()\n",
    "fig.savefig('confusion_matrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_for_single_image(file_name, model, labels):\n",
    "    image_pixels = cv2.imread(file_name, 0)\n",
    "#     print(len(image_pixels))\n",
    "    image_input = image_pixels.reshape(-1, 48, 48, 1)\n",
    "    predicted_emotion = model.predict(image_input, verbose=0)\n",
    "#     print(predicted_emotion)\n",
    "    print(\"This image is classified to be {} with {:.2f}% confidence\".format(\n",
    "        labels[predicted_emotion.argmax()],predicted_emotion.max()*100))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_for_single_image('100th.jpg', model, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_for_single_image('ashok.jpg', model, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_for_single_image('ashok2.png', model, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_for_single_image('rose2.jpg', model, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_for_single_image('rose3.jpg', model, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_for_single_image('jose.png', model, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_for_single_image('rohit_happy.jpeg', model, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_for_single_image('ankita.png', model, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
